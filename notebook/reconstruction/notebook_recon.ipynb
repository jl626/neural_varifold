{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction of Shape Reconstruction method (Neural Spline) proposed By Williams et al. 2021\n",
    "\n",
    "Here, we are going to reproduce Williams et al. methods for shape reconstruction \n",
    "\n",
    "Given $\\mathcal{X} = \\{x_1, \\dots, x_k \\}$ and $\\mathcal{N} = \\{n_1,\\dots, n_k\\}$ and $\\mathcal{Y} = \\{y_1, \\dots, y_k\\}$,  $\\forall y_i = 0$\n",
    "\n",
    "* Define $\\mathcal{X}_{\\delta}^- = \\{x_1 - \\delta n_1, \\dots , x_k - \\delta n_k\\}$ and $\\mathcal{X}_{\\delta}^+ = \\{x_1 + \\delta n_1, \\dots , x_k + \\delta n_k\\}$ and $\\mathcal{Y}_{\\delta}^- = \\{-\\delta, \\dots, -\\delta\\}$ and $\\mathcal{Y}_{\\delta}^+= \\{\\delta, \\dots,\\delta\\}$ in similar manner\n",
    "* With union of the sets $\\hat{\\mathcal{X}} = \\mathcal{X} \\cup \\mathcal{X}_{\\delta}^- \\cup \\mathcal{X}_{\\delta}^+$ and $\\hat{\\mathcal{Y}} = \\mathcal{Y} \\cup \\mathcal{Y}_{\\delta}^- \\cup \\mathcal{Y}_{\\delta}^+$, training data tuple $(\\hat{\\mathcal{X}}, \\hat{\\mathcal{Y}})$ defines the \\textbf{implicit representation of geometric surface}.\n",
    "\n",
    "\n",
    "\n",
    "Let's defiine a regular voxel grids $\\mathcal{X}_{test}$ on which all the extneded point clouds $\\hat{\\mathcal{X}}$ lie.\n",
    "\n",
    "Then the signed distance corresponding the regular grid $\\mathcal{X}_{test}$ can be computed by kernel regression with NTK as follow \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "Y_{test} = K_{(test,train)}  (K_{(train,train)} + \\lambda I )^{-1}  Y_{train}\n",
    "\\end{equation}\n",
    "\n",
    "where, $Y_{train}$ and $Y_{test}$ are the signed distances for the extended point clouds and the regular grids, respectively. \n",
    "\n",
    "\n",
    "![alt text](implicit2.png \"Concept\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append( '..' )\n",
    "import os \n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'\n",
    "import time\n",
    "import jax \n",
    "from absl import app\n",
    "from absl import flags\n",
    "import jax.numpy as np\n",
    "import neural_tangents as nt\n",
    "from neural_tangents import stax\n",
    "from examples import datasets\n",
    "from examples import util\n",
    "from neural_tangents._src.utils.kernel import Kernel\n",
    "import numpy as onp\n",
    "from jax import random\n",
    "# double precision otherwise it may return NaN\n",
    "from jax.config import config ; config.update('jax_enable_x64', True)\n",
    "import sys\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)\n",
    "from utils import *\n",
    "from util import Prod\n",
    "from skimage import measure\n",
    "import trimesh \n",
    "import torch_geometric\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "In this example, we are going to reconstruct a cup from ModelNet40 dataset. \n",
    "\n",
    "The original ModelNet40 dataset is in mesh format. Here, we are going to use a Point Cloud version that processed by  PointNet++ authors (Charles Qi et al. (2018)).\n",
    "\n",
    "\n",
    "Each design consists of 10000 points. Since 3D reconstruction with all 10000 points require a large memory, we are going to subsample only 6144 points instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Loading data.')\n",
    "\n",
    "# hyper parameters\n",
    "onp.random.seed(0)\n",
    "n_train = 6144 # subsample 6144 out of 10000 points \n",
    "\n",
    "\n",
    "\n",
    "# Load data \n",
    "data = onp.loadtxt('/home/juheonlee/learning/pointnet2/data/modelnet40_normal_resampled/chair/chair_0002.txt',delimiter=',')\n",
    "pos = torch.DoubleTensor(data[:n_train,:3]) # convert it Double Precision \n",
    "nor = torch.DoubleTensor(data[:n_train,3:]) # convert it Double Precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter setting\n",
    "\n",
    "Since we are going to reconstruct the shapes by rasterising point clouds with sign distance function. We need to pre define a number of parameters related with the rasterisation\n",
    "\n",
    "* ``nb``: voxel resolution (here 128 X 128 X 128)\n",
    "* ``eps``: $\\delta$ related to generating an extended point cloud data\n",
    "* ``scaled box``: rescaling shape with a scaling parameter (default: 1.1)\n",
    "* ``out_grid_size``: output grid size\n",
    "* ``eps_word_coords``: adjusted $\\delta$ considering the scaling effect. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D regular grid structure parameters \n",
    "nb = 128  # voxel resolution (128 X 128 X 128) \n",
    "eps = 0.5 # \n",
    "scaled_bbox = point_cloud_bounding_box(pos, 1.1) # compute bound eq: (max_val_per_axis - min_val_per_axis)/scale_param\n",
    "print(scaled_bbox)\n",
    "out_grid_size = torch.round(scaled_bbox[1] / scaled_bbox[1].max() * nb).to(torch.int32)   \n",
    "voxel_size = scaled_bbox[1] / out_grid_size  # size of one voxel\n",
    "eps_world_coords = eps * torch.norm(voxel_size).item()\n",
    "print(eps_world_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to pre-process the point clouds by moving it towards normal direction with parameter $\\delta$\n",
    "\n",
    "``triple_points_along_normals`` takes inputs (position, normal, $\\delta$), then returns the extended dataset $\\mathcal{X}_train$ and its signed distance values $Y_{train}$\n",
    "\n",
    "Then we normalise and transform the extended point clouds to lie on the regular 3D voxel grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing of the point clouds \n",
    "\n",
    "# step 1 - generate extended dataset by moving orignial point clouds towards positive/negative directions toward the normals * eps i.e. data size = N_points * 3 X 3\n",
    "print(pos.shape)\n",
    "x_train, y_train = triple_points_along_normals(pos, nor, eps_world_coords, homogeneous=False)\n",
    "print(x_train.shape)\n",
    "\n",
    "# step 2 - normalize point clouds: as we are going to estimate SDF for all regular grid points \n",
    "tx = normalize_pointcloud_transform(x_train)\n",
    "\n",
    "\n",
    "# step 3 conduct affine transform to fit the shape into the regular grid box we chose\n",
    "x_train = affine_transform_pointcloud(x_train, tx)\n",
    "\n",
    "# step 4 - convert the data from PyTorch to numpy format \n",
    "x_train = x_train.numpy()\n",
    "y_train = y_train.unsqueeze(-1).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating regular 3D voxel grid coordinates \n",
    "\n",
    "In this method, we are going to assign sign distance function for every coordinates in the regular voxel grid that sie of ``nb`` X ``nb`` X ``nb``.\n",
    "\n",
    "In order to reduce the computational costs, we are reducting the number of query grid points by croping the regular grids. \n",
    "\n",
    "It is can be done by computing ``cell_vox_min`` and ``cell_vox_max``, which gives the minimum volume to cover the shape. \n",
    "\n",
    "The generation of regular 3D voxel grid was done by ``np.mgrid`` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_origin, bbox_size = scaled_bbox\n",
    "voxel_size = bbox_size / out_grid_size  # size of a single voxel cell\n",
    "\n",
    "cell_vox_min = torch.tensor([0, 0, 0], dtype=torch.int32)\n",
    "cell_vox_max = out_grid_size\n",
    "\n",
    "\n",
    "print(f\"Evaluating model on grid of size {[_.item() for _ in (cell_vox_max - cell_vox_min)]}.\")\n",
    "eval_start_time = time.time()\n",
    "\n",
    "xmin = bbox_origin + (cell_vox_min + 0.5) * voxel_size\n",
    "xmax = bbox_origin + (cell_vox_max - 0.5) * voxel_size\n",
    "\n",
    "xmin = affine_transform_pointcloud(xmin.unsqueeze(0), tx).squeeze()\n",
    "xmax = affine_transform_pointcloud(xmax.unsqueeze(0), tx).squeeze()\n",
    "\n",
    "xmin, xmax = xmin.numpy(), xmax.numpy()\n",
    "cell_vox_size = (cell_vox_max - cell_vox_min).numpy()\n",
    "\n",
    "# generate regular voxel\n",
    "xgrid = np.stack([_.ravel() for _ in np.mgrid[xmin[0]:xmax[0]:cell_vox_size[0] * 1j,\n",
    "                                                xmin[1]:xmax[1]:cell_vox_size[1] * 1j,\n",
    "                                                xmin[2]:xmax[2]:cell_vox_size[2] * 1j]], axis=-1)\n",
    "print(xgrid.shape)\n",
    "xgrid = torch.from_numpy(xgrid).to(torch.float64)\n",
    "x_test = xgrid.to(torch.float64).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Network (1-layer fully connected network)\n",
    "\n",
    "One can use a number of different architecture. According to Williams et al (2021), 1-layer infinite-width neural network is sufficient to infer sign distance functions for all grid points.\n",
    "\n",
    "Note that there are two ways to compute infinite-width neural networks \n",
    "\n",
    "``Neural Gaussian Process (NNGP)``: it corresponds to the network that fixes all layers but the last one with MSE loss. \n",
    "``Neural Tangent Kernel (NTK)``: it corresponds to regular training strategy with MSE loss\n",
    "\n",
    "In thier paper, they uses NNGP for their experiments and named it as ``neural splines``\n",
    "\n",
    "\n",
    "Note that our experiment shows that ``NTK`` and ``NNGP`` have a completely different hyper-parameter dynamics. \n",
    "\n",
    "``NNGP`` tends to follow more standard ``NTK//NNGP`` weight/bias initialisation framework, while ``NTK`` require quite a large value for bias initialisation parameter (around 100~1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print('build infinite network')\n",
    "# Build the infinite network.\n",
    "layers = []\n",
    "for _ in range(1):\n",
    "  layers += [stax.Dense(1, 1., 100.0), stax.Relu()]\n",
    "init_fn, apply_fn, kernel_fn = stax.serial(*(layers))\n",
    "\n",
    "# Optionally, compute the kernel in batches, in parallel.\n",
    "kernel_fn = nt.batch(kernel_fn,\n",
    "                    device_count=0,\n",
    "                    batch_size=n_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute signed distance using NTK/NNGP\n",
    "\n",
    "Computing signed distance values for the regular 3D voxel grids are as straightward as the classification. \n",
    "\n",
    "We used ``gradient_descent_mse_ensemble`` i.e. the standard kernel regression with NNGP/NTK. \n",
    "\n",
    "Since the size of the regular 3D voxel grid data is large, we batch processed and predict the signed distance for every regular 3D voxels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "print('train kernel')\n",
    "# Bayesian and infinite-time gradient descent inference with infinite network.\n",
    "predict_fn = nt.predict.gradient_descent_mse_ensemble(kernel_fn, x_train,y_train, diag_reg=1e-6)\n",
    "\n",
    "n_batch=1024\n",
    "nngp = []\n",
    "ntk  = []\n",
    "print('inference kenrel')\n",
    "# batch process (otherwise cost too much memory)\n",
    "for i in range(len(x_test)//n_batch):\n",
    "    if i == (len(x_test)//n_batch) -1:\n",
    "        x2 = x_test[int(i*n_batch):]\n",
    "    else:\n",
    "        x2 = x_test[int(i*n_batch):int((i+1)*n_batch)]\n",
    "    fx_test_nngp, fx_test_ntk = predict_fn(x_test=x2)\n",
    "    fx_test_nngp.block_until_ready()\n",
    "    fx_test_ntk.block_until_ready()\n",
    "    ntk.append(onp.array(fx_test_ntk))\n",
    "    nngp.append(onp.array(fx_test_nngp))\n",
    "\n",
    "# merge\n",
    "ntk  = onp.concatenate(ntk,0)\n",
    "nngp = onp.concatenate(nngp,0)\n",
    "ntk  = ntk.reshape(tuple(cell_vox_size.astype(np.int32)))\n",
    "nngp = nngp.reshape(tuple(cell_vox_size.astype(np.int32)))\n",
    "duration = time.time() - start\n",
    "print('Kernel construction and inference done in %s seconds.' % duration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signed Distance function \n",
    "\n",
    "The result shows the signed distance function for the regular 3D voxel grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ntk[:,:,40]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "x = np.linspace(-1, 1, example.shape[0])\n",
    "y = np.linspace(-1, 1, example.shape[1])\n",
    "X, Y = np.meshgrid(x, y)\n",
    "ax.contourf(X, Y, example.T)\n",
    "  \n",
    "ax.set_title('Contour Plot')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NTK reconstruction\n",
    "\n",
    "Given the signed distance function representation (i.e. implicit representation), we are goingto reconstruct 3D meshes by marching cube algorithm\n",
    "\n",
    "The given signed distance function, reconstruction result is shown as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#c = ntk.reshape(nb,nb,nb)\n",
    "verts, faces, normals, values = measure.marching_cubes(ntk, level=0.0, spacing=voxel_size)\n",
    "tri_mesh = trimesh.Trimesh(np.asarray(verts), np.asarray(faces),\n",
    "                          vertex_normals=np.asarray(normals))\n",
    "tri_mesh.visual.vertex_colors = trimesh.visual.random_color()\n",
    "tri_mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file \n",
    "mesh = o3d.geometry.TriangleMesh()\n",
    "mesh.vertices = o3d.utility.Vector3dVector(verts+bbox_origin.numpy())\n",
    "mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "mesh.triangle_normals = o3d.utility.Vector3dVector(normals)\n",
    "o3d.io.write_triangle_mesh(\"chair_spline.ply\", mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNGP reconstruction\n",
    "\n",
    "We reconstruct 3D meshes from the implicit representation computed by NNGP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts, faces, normals, values = measure.marching_cubes_lewiner(nngp, level=0.0, spacing=voxel_size)  # convert sign distance function to 3D meshes by marching cube algorithm\n",
    "tri_mesh = trimesh.Trimesh(np.asarray(verts), np.asarray(faces),vertex_normals=np.asarray(normals))\n",
    "tri_mesh.visual.vertex_colors = trimesh.visual.random_color()\n",
    "tri_mesh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "mesh = o3d.geometry.TriangleMesh()\n",
    "mesh.vertices = o3d.utility.Vector3dVector(verts)\n",
    "mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "mesh.triangle_normals = o3d.utility.Vector3dVector(normals)\n",
    "#o3d.io.write_triangle_mesh(\"cup_vari_nngp_1_1000_IGR_sample2048.ply\", mesh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('neural-varifold')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "f0f8e4c58790b2473c7502eb8a75f8493550d236d6abaa920eb226ed2184a4cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
