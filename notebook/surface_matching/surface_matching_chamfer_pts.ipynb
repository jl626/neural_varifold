{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append( '../..' )\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from pytorch3d.io import load_obj, save_obj\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "import numpy as np\n",
    "from energy import tangent_kernel\n",
    "\n",
    "# Set the device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"WARNING: CPU only, this will be slow!\")\n",
    "import input_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'cup'\n",
    "#experiment_name = 'dolphin'\n",
    "#experiment_name = 'hippo'\n",
    "#experiment_name = 'bunny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No functional values found: set to 0\n",
      "No functional values found: set to 0\n",
      "(15146, 3)\n",
      "(15004, 3)\n",
      "(473, 3)\n",
      "(493, 3)\n"
     ]
    }
   ],
   "source": [
    "# We read the target 3D model using load_obj\n",
    "# case 1.  \"Cup\"\n",
    "low = 31\n",
    "mid = 26\n",
    "high = 20\n",
    "if experiment_name=='cup':\n",
    "    # two different Cups \n",
    "    [VS,FS,FunS] = input_output.loadData(\"../../data/matching/cup2.ply\")\n",
    "    [VT,FT,FunT] = input_output.loadData(\"../../data/matching/cup3_broken.ply\")\n",
    "    source = [VS,FS]\n",
    "    target= [VT,FT]\n",
    "    # original size\n",
    "    print(VS.shape)\n",
    "    print(VT.shape)\n",
    "    # Option 1 Sampling\n",
    "    # Decimate source mesh to compute initialization for the multires algorithm \n",
    "    param_decimation = {'factor':31/32,'Vol_preser':1, 'Fun_Error_Metric': 1, 'Fun_weigth':0.00} #decimate by a factor of 32\n",
    "    [verts1,faces1]= input_output.decimate_mesh(VS,FS,param_decimation)\n",
    "    print(verts1.shape)\n",
    "    param_decimation = {'factor':31/32,'Vol_preser':1, 'Fun_Error_Metric': 1, 'Fun_weigth':0.00} #decimate by a factor of 32\n",
    "    [verts2,faces2]= input_output.decimate_mesh(VT,FT,param_decimation)\n",
    "    print(verts2.shape)\n",
    "    verts1 = torch.FloatTensor(verts1)\n",
    "    verts2 = torch.FloatTensor(verts2)\n",
    "    faces1 = torch.LongTensor(faces1)\n",
    "    faces2 = torch.LongTensor(faces2)\n",
    "    save_obj('../../results/cup2_mid.obj', verts1, faces1)\n",
    "    save_obj('../../results/cup3_broken_mid.obj', verts2, faces2)\n",
    "# Case 2 Dolphin\n",
    "elif experiment_name == 'dolphin':\n",
    "    # sphere to dolphine \n",
    "    src_mesh = ico_sphere(4)\n",
    "    VT, FT, FunS = load_obj(\"../../data/matching/dolphin.obj\")\n",
    "    VS, FS = src_mesh.verts_packed(), src_mesh.faces_packed()\n",
    "    verts1, faces1 = VS, FS\n",
    "    verts2, faces2 = VT, FT.verts_idx\n",
    "    \n",
    "# Case 3 Hippocampus \n",
    "elif experiment_name == 'hippo':\n",
    "    verts1, faces1, verts2, faces2 = torch.load('../../data/matching/hippos_red.pt')\n",
    "    save_obj('../../results/hippo_source_low.obj', verts1, faces1)\n",
    "    save_obj('../../results/hippo_target_low.obj', verts2, faces2)\n",
    "\n",
    "    #verts1, faces1, verts2, faces2 = torch.load('../../data/matching/hippos_red.pt')\n",
    "    #save_obj('../../results/hippo_source.obj', verts1, faces1)\n",
    "    #save_obj('../../results/hippo_target.obj', verts2, faces2)\n",
    "\n",
    "# Case 2 Dolphin\n",
    "elif experiment_name == 'bunny':\n",
    "    # sphere to dolphine \n",
    "    src_mesh = ico_sphere(4)\n",
    "    VT, FT, FunS = load_obj(\"../../data/matching/bunny.obj\")\n",
    "    VS, FS = src_mesh.verts_packed(), src_mesh.faces_packed()\n",
    "    # Decimate source mesh to compute initialization for the multires algorithm \n",
    "    param_decimation = {'factor':29/32,'Vol_preser':1, 'Fun_Error_Metric': 1, 'Fun_weigth':0.00} #decimate by a factor of 16\n",
    "    [verts1,faces1]= input_output.decimate_mesh(VS.numpy(),FS.numpy(),param_decimation)\n",
    "    print(verts1.shape)\n",
    "    param_decimation = {'factor':31/32,'Vol_preser':1, 'Fun_Error_Metric': 1, 'Fun_weigth':0.00} #decimate by a factor of 16\n",
    "    [verts2,faces2]= input_output.decimate_mesh(VT.numpy(),FT.verts_idx.numpy(),param_decimation)\n",
    "    print(verts2.shape)\n",
    "    verts1 = torch.FloatTensor(verts1)\n",
    "    verts2 = torch.FloatTensor(verts2)\n",
    "    faces1 = torch.LongTensor(faces1)\n",
    "    faces2 = torch.LongTensor(faces2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([473, 3])\n",
      "torch.Size([493, 3])\n"
     ]
    }
   ],
   "source": [
    "# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
    "# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
    "# For this tutorial, normals and textures are ignored.\n",
    "faces_idx1 = faces1.to(device)\n",
    "faces_idx2 = faces2.to(device)\n",
    "\n",
    "# Mark: obj files\n",
    "#faces_idx1 = faces1.to(device)#.verts_idx.to(device)\n",
    "#faces_idx2 = faces2.verts_idx.to(device)\n",
    "\n",
    "verts1 = verts1.to(device)\n",
    "verts2 = verts2.to(device)\n",
    "# We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
    "# (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
    "# Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
    "#'''\n",
    "center1 = verts1.mean(0)\n",
    "center2 = verts2.mean(0)\n",
    "verts1 = verts1 - center1\n",
    "verts2 = verts2 - center2\n",
    "scale1 = max(verts1.abs().max(0)[0])\n",
    "scale2 = max(verts2.abs().max(0)[0])\n",
    "verts1 = verts1 / scale1\n",
    "verts2 = verts2 / scale2\n",
    "#'''\n",
    "# We construct a Meshes structure for the target mesh\n",
    "src_mesh = Meshes(verts=[verts1], faces=[faces_idx1])\n",
    "trg_mesh = Meshes(verts=[verts2], faces=[faces_idx2])\n",
    "print(verts1.shape)\n",
    "print(verts2.shape)\n",
    "#save_obj('../../results/cup2.obj',verts1,faces1)\n",
    "#save_obj('../../results/cup3_broken.obj',verts2,faces2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(testnet, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(6,64),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(64,128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128,3))\n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer setting\n",
    "models = testnet().cuda()\n",
    "optimizer = torch.optim.Adam(models.parameters(), lr=.001)\n",
    "# Number of optimization steps\n",
    "Niter = 100001\n",
    "\n",
    "# loss parameters\n",
    "# Weight for the chamfer loss\n",
    "w_chamfer = 1.0 \n",
    "# Plot period for the losses\n",
    "plot_period = 1000\n",
    "\n",
    "chamfer_losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Iter: total_loss 0.054405 Chamfer_loss 0.054405 Varifold loss 0.00000000\n",
      "current best loss is 0: 0.054405\n",
      "1000 Iter: total_loss 0.001266 Chamfer_loss 0.001266 Varifold loss 0.00000000\n",
      "current best loss is 994: 0.001229\n",
      "2000 Iter: total_loss 0.001233 Chamfer_loss 0.001233 Varifold loss 0.00000000\n",
      "current best loss is 1822: 0.001172\n",
      "3000 Iter: total_loss 0.001196 Chamfer_loss 0.001196 Varifold loss 0.00000000\n",
      "current best loss is 2681: 0.001152\n",
      "4000 Iter: total_loss 0.001178 Chamfer_loss 0.001178 Varifold loss 0.00000000\n",
      "current best loss is 3915: 0.001145\n",
      "5000 Iter: total_loss 0.001169 Chamfer_loss 0.001169 Varifold loss 0.00000000\n",
      "current best loss is 4408: 0.001140\n",
      "6000 Iter: total_loss 0.001168 Chamfer_loss 0.001168 Varifold loss 0.00000000\n",
      "current best loss is 5867: 0.001134\n",
      "7000 Iter: total_loss 0.001166 Chamfer_loss 0.001166 Varifold loss 0.00000000\n",
      "current best loss is 6540: 0.001122\n",
      "8000 Iter: total_loss 0.001168 Chamfer_loss 0.001168 Varifold loss 0.00000000\n",
      "current best loss is 7646: 0.001121\n",
      "9000 Iter: total_loss 0.001168 Chamfer_loss 0.001168 Varifold loss 0.00000000\n",
      "current best loss is 8614: 0.001121\n",
      "10000 Iter: total_loss 0.001166 Chamfer_loss 0.001166 Varifold loss 0.00000000\n",
      "current best loss is 9158: 0.001113\n",
      "11000 Iter: total_loss 0.001173 Chamfer_loss 0.001173 Varifold loss 0.00000000\n",
      "current best loss is 10239: 0.001106\n",
      "12000 Iter: total_loss 0.001125 Chamfer_loss 0.001125 Varifold loss 0.00000000\n",
      "current best loss is 11258: 0.001103\n",
      "13000 Iter: total_loss 0.001146 Chamfer_loss 0.001146 Varifold loss 0.00000000\n",
      "current best loss is 12597: 0.001103\n",
      "14000 Iter: total_loss 0.001137 Chamfer_loss 0.001137 Varifold loss 0.00000000\n",
      "current best loss is 13799: 0.001100\n",
      "15000 Iter: total_loss 0.001143 Chamfer_loss 0.001143 Varifold loss 0.00000000\n",
      "current best loss is 13799: 0.001100\n",
      "16000 Iter: total_loss 0.001145 Chamfer_loss 0.001145 Varifold loss 0.00000000\n",
      "current best loss is 13799: 0.001100\n",
      "17000 Iter: total_loss 0.001131 Chamfer_loss 0.001131 Varifold loss 0.00000000\n",
      "current best loss is 13799: 0.001100\n",
      "18000 Iter: total_loss 0.001149 Chamfer_loss 0.001149 Varifold loss 0.00000000\n",
      "current best loss is 13799: 0.001100\n",
      "19000 Iter: total_loss 0.001134 Chamfer_loss 0.001134 Varifold loss 0.00000000\n",
      "current best loss is 13799: 0.001100\n",
      "20000 Iter: total_loss 0.001152 Chamfer_loss 0.001152 Varifold loss 0.00000000\n",
      "current best loss is 13799: 0.001100\n",
      "21000 Iter: total_loss 0.001140 Chamfer_loss 0.001140 Varifold loss 0.00000000\n",
      "current best loss is 13799: 0.001100\n",
      "22000 Iter: total_loss 0.001164 Chamfer_loss 0.001164 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "23000 Iter: total_loss 0.001125 Chamfer_loss 0.001125 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "24000 Iter: total_loss 0.001155 Chamfer_loss 0.001155 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "25000 Iter: total_loss 0.001141 Chamfer_loss 0.001141 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "26000 Iter: total_loss 0.001146 Chamfer_loss 0.001146 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "27000 Iter: total_loss 0.001155 Chamfer_loss 0.001155 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "28000 Iter: total_loss 0.001121 Chamfer_loss 0.001121 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "29000 Iter: total_loss 0.001130 Chamfer_loss 0.001130 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "30000 Iter: total_loss 0.001155 Chamfer_loss 0.001155 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "31000 Iter: total_loss 0.001140 Chamfer_loss 0.001140 Varifold loss 0.00000000\n",
      "current best loss is 21016: 0.001096\n",
      "32000 Iter: total_loss 0.001128 Chamfer_loss 0.001128 Varifold loss 0.00000000\n",
      "current best loss is 31749: 0.001094\n",
      "33000 Iter: total_loss 0.001155 Chamfer_loss 0.001155 Varifold loss 0.00000000\n",
      "current best loss is 31749: 0.001094\n",
      "34000 Iter: total_loss 0.001138 Chamfer_loss 0.001138 Varifold loss 0.00000000\n",
      "current best loss is 31749: 0.001094\n",
      "35000 Iter: total_loss 0.001159 Chamfer_loss 0.001159 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "36000 Iter: total_loss 0.001144 Chamfer_loss 0.001144 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "37000 Iter: total_loss 0.001165 Chamfer_loss 0.001165 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "38000 Iter: total_loss 0.001136 Chamfer_loss 0.001136 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "39000 Iter: total_loss 0.001148 Chamfer_loss 0.001148 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "40000 Iter: total_loss 0.001113 Chamfer_loss 0.001113 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "41000 Iter: total_loss 0.001138 Chamfer_loss 0.001138 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "42000 Iter: total_loss 0.001141 Chamfer_loss 0.001141 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "43000 Iter: total_loss 0.001137 Chamfer_loss 0.001137 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "44000 Iter: total_loss 0.001146 Chamfer_loss 0.001146 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "45000 Iter: total_loss 0.001134 Chamfer_loss 0.001134 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "46000 Iter: total_loss 0.001157 Chamfer_loss 0.001157 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "47000 Iter: total_loss 0.001126 Chamfer_loss 0.001126 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "48000 Iter: total_loss 0.001149 Chamfer_loss 0.001149 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "49000 Iter: total_loss 0.001152 Chamfer_loss 0.001152 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "50000 Iter: total_loss 0.001144 Chamfer_loss 0.001144 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "51000 Iter: total_loss 0.001151 Chamfer_loss 0.001151 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "52000 Iter: total_loss 0.001137 Chamfer_loss 0.001137 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "53000 Iter: total_loss 0.001123 Chamfer_loss 0.001123 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "54000 Iter: total_loss 0.001132 Chamfer_loss 0.001132 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "55000 Iter: total_loss 0.001133 Chamfer_loss 0.001133 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "56000 Iter: total_loss 0.001147 Chamfer_loss 0.001147 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "57000 Iter: total_loss 0.001139 Chamfer_loss 0.001139 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "58000 Iter: total_loss 0.001157 Chamfer_loss 0.001157 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "59000 Iter: total_loss 0.001160 Chamfer_loss 0.001160 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "60000 Iter: total_loss 0.001129 Chamfer_loss 0.001129 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "61000 Iter: total_loss 0.001139 Chamfer_loss 0.001139 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "62000 Iter: total_loss 0.001174 Chamfer_loss 0.001174 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "63000 Iter: total_loss 0.001141 Chamfer_loss 0.001141 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "64000 Iter: total_loss 0.001131 Chamfer_loss 0.001131 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "65000 Iter: total_loss 0.001132 Chamfer_loss 0.001132 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "66000 Iter: total_loss 0.001133 Chamfer_loss 0.001133 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "67000 Iter: total_loss 0.001139 Chamfer_loss 0.001139 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "68000 Iter: total_loss 0.001159 Chamfer_loss 0.001159 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "69000 Iter: total_loss 0.001133 Chamfer_loss 0.001133 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "70000 Iter: total_loss 0.001143 Chamfer_loss 0.001143 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "71000 Iter: total_loss 0.001141 Chamfer_loss 0.001141 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "72000 Iter: total_loss 0.001158 Chamfer_loss 0.001158 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "73000 Iter: total_loss 0.001138 Chamfer_loss 0.001138 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "74000 Iter: total_loss 0.001155 Chamfer_loss 0.001155 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "75000 Iter: total_loss 0.001132 Chamfer_loss 0.001132 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "76000 Iter: total_loss 0.001136 Chamfer_loss 0.001136 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "77000 Iter: total_loss 0.001166 Chamfer_loss 0.001166 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "78000 Iter: total_loss 0.001141 Chamfer_loss 0.001141 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "79000 Iter: total_loss 0.001167 Chamfer_loss 0.001167 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "80000 Iter: total_loss 0.001154 Chamfer_loss 0.001154 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "81000 Iter: total_loss 0.001157 Chamfer_loss 0.001157 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "82000 Iter: total_loss 0.001135 Chamfer_loss 0.001135 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "83000 Iter: total_loss 0.001123 Chamfer_loss 0.001123 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "84000 Iter: total_loss 0.001160 Chamfer_loss 0.001160 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "85000 Iter: total_loss 0.001127 Chamfer_loss 0.001127 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "86000 Iter: total_loss 0.001173 Chamfer_loss 0.001173 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "87000 Iter: total_loss 0.001153 Chamfer_loss 0.001153 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "88000 Iter: total_loss 0.001135 Chamfer_loss 0.001135 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "89000 Iter: total_loss 0.001146 Chamfer_loss 0.001146 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "90000 Iter: total_loss 0.001151 Chamfer_loss 0.001151 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "91000 Iter: total_loss 0.001154 Chamfer_loss 0.001154 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "92000 Iter: total_loss 0.001144 Chamfer_loss 0.001144 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "93000 Iter: total_loss 0.001123 Chamfer_loss 0.001123 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "94000 Iter: total_loss 0.001152 Chamfer_loss 0.001152 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "95000 Iter: total_loss 0.001130 Chamfer_loss 0.001130 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "96000 Iter: total_loss 0.001153 Chamfer_loss 0.001153 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "97000 Iter: total_loss 0.001151 Chamfer_loss 0.001151 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "98000 Iter: total_loss 0.001146 Chamfer_loss 0.001146 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "99000 Iter: total_loss 0.001151 Chamfer_loss 0.001151 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n",
      "100000 Iter: total_loss 0.001155 Chamfer_loss 0.001155 Varifold loss 0.00000000\n",
      "current best loss is 34409: 0.001089\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best = None\n",
    "best_loss = 0\n",
    "best_iter = 0\n",
    "for i in range(Niter):\n",
    "    # Initialize optimizer\n",
    "    optimizer.zero_grad()\n",
    "    # model train\n",
    "    sv, sf = src_mesh.get_mesh_verts_faces(0)\n",
    "    sn = src_mesh.verts_normals_packed()\n",
    "    inputs = torch.cat([sv.cuda(),sn.cuda()],1)\n",
    "    deform_verts = models(inputs) \n",
    "\n",
    "    # Deform the mesh\n",
    "    new_src_mesh = src_mesh.offset_verts(deform_verts)\n",
    "    f1 = new_src_mesh.faces_packed()\n",
    "    v1 = new_src_mesh.verts_packed()\n",
    "\n",
    "    # We sample 8k points from the surface of each mesh \n",
    "    sample_trg = sample_points_from_meshes(trg_mesh, 4096*2)\n",
    "    sample_src = sample_points_from_meshes(new_src_mesh, 4096*2)\n",
    "    \n",
    "    # We compare the two sets of pointclouds by computing (a) the chamfer loss\n",
    "    loss_chamfer, _ = chamfer_distance(sample_src, sample_trg)\n",
    "    \n",
    "    loss_varifold = 0.  \n",
    "    # Weighted sum of the losses\n",
    "    loss =  loss_chamfer*w_chamfer\n",
    "    \n",
    "    if best_loss == 0:\n",
    "        best = deform_verts\n",
    "        best_loss = loss.detach()\n",
    "        best_iter = 0\n",
    "    elif best_loss > loss.detach():\n",
    "        best = deform_verts\n",
    "        best_loss = loss.detach()\n",
    "        best_iter = i\n",
    "        torch.save(models.state_dict(),'../../results/chamfer_%s_n.pth'%experiment_name)\n",
    "\n",
    "    # Print the losses\n",
    "    if i % plot_period==0:\n",
    "        print('%d Iter: total_loss %.6f Chamfer_loss %.6f Varifold loss %.8f'% (i,loss,loss_chamfer, loss_varifold))\n",
    "        print('current best loss is %d: %.6f'%(best_iter,best_loss))\n",
    "    \n",
    "    # Save the losses for plotting\n",
    "    chamfer_losses.append(float(loss_chamfer.detach().cpu()))\n",
    "        \n",
    "    # Optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Fetch the verts and faces of the final predicted mesh\n",
    "new_src_mesh = src_mesh.offset_verts(best)\n",
    "final_verts, final_faces = new_src_mesh.get_mesh_verts_faces(0)\n",
    "\n",
    "# Scale normalize back to the original target size\n",
    "final_verts = (final_verts) * scale2 + center2\n",
    "\n",
    "# Store the predicted mesh using save_obj\n",
    "save_obj('../../results/chamfer_%s_low.obj'%(experiment_name), final_verts, final_faces)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final Chamfer distance: 0.012942\n"
     ]
    }
   ],
   "source": [
    "final_chamfer,_ = chamfer_distance((final_verts.unsqueeze(0).double() - center2)/scale2, verts2.unsqueeze(0).double())\n",
    "print('final Chamfer distance: %.6f'%(final_chamfer.detach().cpu().numpy()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
